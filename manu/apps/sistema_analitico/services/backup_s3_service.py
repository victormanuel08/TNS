"""
Servicio para gestionar backups de bases de datos Firebird a S3.
"""
import os
import subprocess
import logging
import time
from datetime import datetime, date
from typing import Dict, List, Optional, Tuple
from django.utils import timezone
from django.db.models import Q

from ..models import (
    EmpresaServidor, ConfiguracionS3, BackupS3
)

logger = logging.getLogger(__name__)

try:
    import boto3
    from botocore.config import Config as BotoConfig
    from botocore.exceptions import ClientError, BotoCoreError
    BOTO3_AVAILABLE = True
except ImportError:
    BOTO3_AVAILABLE = False
    BotoConfig = None
    logger.warning("boto3 no est√° instalado. Los backups a S3 no funcionar√°n.")


class BackupS3Service:
    """
    Servicio para realizar backups de bases de datos Firebird a S3.
    """
    
    def __init__(self, configuracion_s3: ConfiguracionS3):
        """
        Inicializa el servicio con una configuraci√≥n S3.
        
        Args:
            configuracion_s3: Configuraci√≥n S3 a utilizar
        """
        if not BOTO3_AVAILABLE:
            raise ImportError("boto3 no est√° instalado. Instala con: pip install boto3")
        
        self.config = configuracion_s3
        
        # Configurar cliente S3
        s3_kwargs = {
            'aws_access_key_id': configuracion_s3.access_key_id,
            'aws_secret_access_key': configuracion_s3.secret_access_key,
            'region_name': configuracion_s3.region,
        }
        
        if configuracion_s3.endpoint_url:
            # Para servicios S3-compatibles (como Contabo, MinIO), usar path-style
            endpoint_url = configuracion_s3.endpoint_url
            s3_kwargs['endpoint_url'] = endpoint_url
            
            # Force path-style para servicios S3-compatibles (no AWS)
            # Path-style: https://s3.contabo.com/bucket-name/key
            # Virtual-hosted: https://bucket-name.s3.contabo.com/key
            if BotoConfig:
                # Para Contabo, usar path-style expl√≠citamente
                s3_config = BotoConfig(
                    signature_version='s3v4',
                    s3={
                        'addressing_style': 'path'  # Forzar path-style para Contabo
                    },
                    # Tambi√©n configurar retries y timeouts
                    retries={
                        'max_attempts': 3,
                        'mode': 'standard'
                    },
                    # Timeouts para evitar bloqueos indefinidos
                    connect_timeout=30,  # 30 segundos para conectar
                    read_timeout=300,    # 5 minutos para leer (upload de archivos grandes)
                    max_pool_connections=10
                )
                s3_kwargs['config'] = s3_config
                logger.info(f"Configurando S3 con endpoint: {endpoint_url}, path-style: True")
                logger.debug(f"Config S3: {s3_config}")
            else:
                logger.warning("BotoConfig no disponible, puede que path-style no funcione correctamente")
        
        try:
            self.s3_client = boto3.client('s3', **s3_kwargs)
            self.bucket_name = configuracion_s3.bucket_name
            
            # Verificar que el bucket existe y es accesible
            try:
                self.s3_client.head_bucket(Bucket=self.bucket_name)
                logger.info(f"Cliente S3 creado exitosamente. Bucket: {self.bucket_name} (verificado)")
            except ClientError as e:
                error_code = e.response.get('Error', {}).get('Code', 'Unknown')
                if error_code == '404':
                    logger.warning(f"‚ö†Ô∏è Bucket '{self.bucket_name}' no existe. Aseg√∫rate de crearlo en Contabo.")
                elif error_code == '403':
                    logger.warning(f"‚ö†Ô∏è Sin permisos para acceder al bucket '{self.bucket_name}'. Verifica las credenciales.")
                else:
                    logger.warning(f"‚ö†Ô∏è Error verificando bucket '{self.bucket_name}': {error_code}")
                logger.info(f"Cliente S3 creado. Bucket: {self.bucket_name} (no verificado)")
        except Exception as e:
            logger.error(f"Error creando cliente S3: {e}", exc_info=True)
            raise
    
    def obtener_ruta_s3(self, empresa: EmpresaServidor, nombre_archivo: str) -> str:
        """
        Genera la ruta S3 para un backup seg√∫n la estructura:
        {server_name}/{nit_normalizado}/{anio_fiscal}/backups/{nombre_archivo}
        
        Args:
            empresa: Empresa para la cual se genera la ruta
            nombre_archivo: Nombre del archivo de backup
            
        Returns:
            Ruta completa en S3
        """
        # Normalizar nombre del servidor (sin espacios, caracteres especiales)
        server_name = empresa.servidor.nombre.replace(' ', '_').replace('/', '_').replace('\\', '_')
        return f"{server_name}/{empresa.nit_normalizado}/{empresa.anio_fiscal}/backups/{nombre_archivo}"
    
    def _normalizar_nombre_archivo(self, nombre: str) -> str:
        """
        Normaliza un nombre de archivo para S3 (sin caracteres especiales).
        
        Args:
            nombre: Nombre original
            
        Returns:
            Nombre normalizado
        """
        # Reemplazar caracteres problem√°ticos
        nombre = nombre.replace('/', '_').replace('\\', '_').replace(':', '_')
        nombre = nombre.replace('*', '_').replace('?', '_').replace('"', '_')
        nombre = nombre.replace('<', '_').replace('>', '_').replace('|', '_')
        return nombre.strip()
    
    def registrar_backup_en_log(self, empresa: EmpresaServidor, exito: bool, peso_bytes: Optional[int] = None, 
                                 nombre_archivo: Optional[str] = None, error: Optional[str] = None) -> bool:
        """
        Registra un backup en el archivo de log de la empresa.
        El archivo se llama {razon_social}.txt y est√° en {server_name}/{nit_normalizado}/
        
        Si el archivo no existe, lo crea con un header. Luego apendee cada backup como una l√≠nea de log.
        
        Estructura:
            {server_name}/{nit_normalizado}/{razon_social}.txt
        
        Formato del log:
            [YYYY-MM-DD HH:MM:SS] [√âXITO/ERROR] Backup: {nombre_archivo} | Peso: {peso_mb} MB | {error si fall√≥}
        
        Args:
            empresa: Empresa para la cual registrar el backup
            exito: True si el backup fue exitoso, False si fall√≥
            peso_bytes: Tama√±o del archivo de backup en bytes (si fue exitoso)
            nombre_archivo: Nombre del archivo de backup
            error: Mensaje de error si fall√≥
            
        Returns:
            True si se registr√≥ exitosamente, False si hubo alg√∫n error
        """
        try:
            from datetime import datetime
            
            server_name = empresa.servidor.nombre.replace(' ', '_').replace('/', '_').replace('\\', '_')
            prefix_empresa = f"{server_name}/{empresa.nit_normalizado}/"
            
            # Normalizar raz√≥n social para el nombre del archivo
            razon_social = getattr(empresa, 'razon_social', None) or empresa.nombre or f"Empresa_{empresa.codigo}"
            razon_social_normalizada = self._normalizar_nombre_archivo(razon_social)
            nombre_txt = f"{razon_social_normalizada}.txt"
            ruta_s3_txt = f"{prefix_empresa}{nombre_txt}"
            
            # Verificar si el archivo ya existe
            contenido_existente = ""
            try:
                response = self.s3_client.get_object(Bucket=self.bucket_name, Key=ruta_s3_txt)
                contenido_existente = response['Body'].read().decode('utf-8')
            except ClientError as e:
                if e.response.get('Error', {}).get('Code') != 'NoSuchKey':
                    # Error diferente a "no existe", registrar y continuar
                    logger.warning(f"Error leyendo archivo de log existente: {e}")
                # Si no existe, contenido_existente queda vac√≠o y crearemos el header
            
            # Preparar la l√≠nea de log
            fecha_hora = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            estado = "√âXITO" if exito else "ERROR"
            
            # Formatear peso
            if peso_bytes and peso_bytes > 0:
                peso_mb = peso_bytes / (1024 * 1024)
                peso_str = f"{peso_mb:.2f} MB"
            else:
                peso_str = "N/A"
            
            # Construir l√≠nea de log
            linea_log = f"[{fecha_hora}] [{estado}]"
            if nombre_archivo:
                linea_log += f" Backup: {nombre_archivo}"
            linea_log += f" | Peso: {peso_str}"
            if not exito and error:
                linea_log += f" | Error: {error}"
            linea_log += "\n"
            
            # Si el archivo no existe, crear header primero
            if not contenido_existente:
                header = f"=== LOG DE BACKUPS - {razon_social} ===\n"
                header += f"NIT: {empresa.nit_normalizado}\n"
                if getattr(empresa, 'nit', None):
                    header += f"NIT original: {empresa.nit}\n"
                if getattr(empresa, 'representante_legal', None):
                    header += f"Representante Legal: {empresa.representante_legal}\n"
                header += f"C√≥digo: {empresa.codigo}\n"
                header += f"Servidor: {empresa.servidor.nombre}\n"
                header += "=" * 50 + "\n\n"
                contenido_existente = header
            
            # Agregar la nueva l√≠nea de log
            nuevo_contenido = contenido_existente + linea_log
            
            # Subir el archivo actualizado
            contenido_bytes = nuevo_contenido.encode('utf-8')
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=ruta_s3_txt,
                Body=contenido_bytes,
                ContentType='text/plain; charset=utf-8'
            )
            
            logger.debug(f"Backup registrado en log: {ruta_s3_txt}")
            return True
                    
        except Exception as e:
            logger.error(f"Error registrando backup en log para {empresa.nombre}: {e}", exc_info=True)
            return False
    
    def obtener_tamano_actual_gb(self, empresa: EmpresaServidor) -> float:
        """
        Calcula el tama√±o total en GB usado en S3 por una empresa (por servidor y NIT normalizado),
        considerando TODOS los a√±os fiscales, backups y dem√°s carpetas/documentos.
        
        Args:
            empresa: EmpresaServidor espec√≠fica (se usa servidor.nombre + nit_normalizado)
            
        Returns:
            Tama√±o total en GB
        """
        try:
            # Estructura: {server_name}/{nit_normalizado}/{anio_fiscal}/backups/{archivo}
            # El l√≠mite es por empresa (servidor + NIT normalizado), sumando:
            # - Todos los a√±os fiscales
            # - Todos los backups
            # - Cualquier otra carpeta/documento bajo ese prefijo.
            server_name = empresa.servidor.nombre.replace(' ', '_').replace('/', '_').replace('\\', '_')
            prefix = f"{server_name}/{empresa.nit_normalizado}/"
            total_bytes = 0
            
            # Para path-style, el bucket debe ir en la ruta, no en el dominio
            # Usar list_objects_v2 con el bucket en el par√°metro
            logger.debug(f"Listando objetos en S3 con prefix: {prefix}, bucket: {self.bucket_name}")
            paginator = self.s3_client.get_paginator('list_objects_v2')
            for page in paginator.paginate(Bucket=self.bucket_name, Prefix=prefix):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        total_bytes += obj['Size']
            
            return round(total_bytes / (1024 * 1024 * 1024), 2)
        except Exception as e:
            logger.error(f"Error calculando tama√±o de backups para {empresa.nombre}: {e}")
            return 0.0
    
    def crear_backup_firebird(
        self,
        empresa: EmpresaServidor,
        gbak_path: Optional[str] = None,
        usuario: str = "SYSDBA",
        contrasena: str = "masterkey"
    ) -> Tuple[bool, Optional[str], Optional[int]]:
        """
        Crea un backup de la base de datos Firebird de una empresa.
        
        Args:
            empresa: Empresa para la cual crear el backup
            gbak_path: Ruta al ejecutable gbak.exe
            usuario: Usuario de Firebird
            contrasena: Contrase√±a de Firebird
            
        Returns:
            Tupla (√©xito, ruta_archivo_temporal, tamano_bytes)
        """
        if not empresa.ruta_base:
            logger.error(f"Empresa {empresa.nombre} no tiene ruta_base configurada")
            return False, None, None

        # Construir ruta completa considerando servidor remoto
        # Si ruta_base es una ruta local, usarla directamente
        # Si el servidor es remoto, usar formato host:ruta_base para gbak
        servidor_host = empresa.servidor.host
        ruta_completa = empresa.ruta_base
        
        # Si el servidor no es localhost/127.0.0.1, construir ruta remota
        if servidor_host and servidor_host not in ['localhost', '127.0.0.1', '::1']:
            # Para backup remoto, gbak usa formato: host:ruta_base
            # IMPORTANTE: Para rutas de Windows con caracteres especiales (como √ë), 
            # usar formato TCP/IP con puerto expl√≠cito para evitar errores de transliteraci√≥n
            puerto_firebird = empresa.servidor.puerto or 3050
            ruta_base_encoded = empresa.ruta_base
            
            # Si la ruta contiene caracteres especiales, usar formato host/port:ruta
            # Esto ayuda a gbak en Linux a manejar mejor los caracteres especiales de Windows
            # Verificar si hay caracteres no ASCII en la ruta
            tiene_caracteres_especiales = any(ord(c) > 127 for c in ruta_base_encoded)
            
            if tiene_caracteres_especiales:
                # Usar formato con puerto expl√≠cito para mejor compatibilidad con caracteres especiales
                ruta_completa = f"{servidor_host}/{puerto_firebird}:{ruta_base_encoded}"
                logger.info(f"üåê Usando ruta remota con puerto expl√≠cito (caracteres especiales detectados): {ruta_completa}")
            else:
                # Formato est√°ndar para rutas sin caracteres especiales
                ruta_completa = f"{servidor_host}:{ruta_base_encoded}"
                logger.info(f"üåê Usando ruta remota para backup: {ruta_completa}")
            
            logger.info(f"   Verificando conectividad con {servidor_host}...")
            
            # Verificar conectividad b√°sica (puerto 3050) antes de intentar backup
            import socket
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(5)  # 5 segundos timeout
                resultado_ping = sock.connect_ex((servidor_host, 3050))
                sock.close()
                
                if resultado_ping != 0:
                    logger.warning(f"‚ö†Ô∏è No se puede conectar al puerto 3050 de {servidor_host}")
                    logger.warning(f"   Esto puede causar que el backup falle")
                    logger.warning(f"   Verificar: Firebird corriendo, firewall, VPN")
                else:
                    logger.info(f"‚úÖ Conexi√≥n al puerto 3050 de {servidor_host} exitosa")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è No se pudo verificar conectividad con {servidor_host}: {e}")
        else:
            # Verificar que existe localmente
            if not os.path.exists(empresa.ruta_base):
                logger.error(f"Archivo de base de datos no existe localmente: {empresa.ruta_base}")
                return False, None, None
        # Determinar ruta de gbak de forma portable:
        # - Si se pasa expl√≠citamente, usarla.
        # - Si no, leer FIREBIRD_GBAK_PATH de settings.
        # - Si no existe, usar una ruta por defecto seg√∫n el SO.
        if gbak_path is None:
            try:
                from django.conf import settings
                gbak_path = getattr(settings, "FIREBIRD_GBAK_PATH", None)
            except Exception:
                gbak_path = None

        if gbak_path is None:
            # Buscar gbak.exe en ubicaciones comunes
            if os.name == "nt":
                # Rutas comunes de Firebird en Windows
                # Orden: primero (x86) porque es m√°s com√∫n en sistemas de 64 bits
                posibles_rutas = [
                    r"C:\Program Files (x86)\Firebird\Firebird_2_5\bin\gbak.exe",  # M√°s com√∫n
                    r"C:\Program Files (x86)\Firebird\Firebird_3_0\bin\gbak.exe",
                    r"C:\Program Files\Firebird\Firebird_2_5\bin\gbak.exe",
                    r"C:\Program Files\Firebird\Firebird_3_0\bin\gbak.exe",
                    r"C:\Program Files\Firebird\Firebird_4_0\bin\gbak.exe",
                    r"C:\Firebird\bin\gbak.exe",
                ]
                gbak_path = None
                logger.info(f"Buscando gbak.exe en {len(posibles_rutas)} ubicaciones...")
                for ruta in posibles_rutas:
                    existe = os.path.exists(ruta)
                    logger.debug(f"Verificando: {ruta} - Existe: {existe}")
                    if existe:
                        gbak_path = ruta
                        logger.info(f"‚úÖ Encontrado gbak.exe en: {ruta}")
                        break
                
                if gbak_path is None:
                    # Intentar buscar en PATH
                    import shutil
                    logger.info("Buscando gbak.exe en PATH del sistema...")
                    gbak_path = shutil.which("gbak.exe")
                    if gbak_path:
                        logger.info(f"‚úÖ Encontrado gbak.exe en PATH: {gbak_path}")
                
                if gbak_path is None:
                    logger.error("‚ùå No se encontr√≥ gbak.exe en ninguna ubicaci√≥n.")
                    logger.error(f"Ubicaciones verificadas: {posibles_rutas}")
                    logger.error("Configure FIREBIRD_GBAK_PATH en settings.py o instale Firebird.")
                    return False, None, None
                
                # Verificar una vez m√°s que existe antes de continuar
                if not os.path.exists(gbak_path):
                    logger.error(f"‚ùå gbak.exe no existe en la ruta encontrada: {gbak_path}")
                    return False, None, None
            else:
                # En Linux/Ubuntu (VPS): gbak normalmente est√° en el PATH despu√©s de instalar Firebird
                # Si no est√°, puede estar en /usr/bin/gbak o /usr/local/bin/gbak
                import shutil
                gbak_path = shutil.which("gbak")
                
                # Si no est√° en PATH, buscar en ubicaciones comunes de Ubuntu
                # IMPORTANTE: Buscar primero Firebird 2.5 (compatible con las bases de datos .GDB)
                if not gbak_path:
                    posibles_rutas_linux = [
                        "/opt/firebird2.5/opt/firebird/bin/gbak",  # Ruta real despu√©s de extraer buildroot.tar.gz
                        "/opt/firebird2.5/bin/gbak",  # Ruta alternativa
                        "/usr/local/bin/gbak",  # Symlink com√∫n (apunta a Firebird 2.5)
                        "/usr/local/firebird2.5/bin/gbak",  # Otra ruta com√∫n
                        "/home/victus/firebird2.5/bin/gbak",  # Ruta en home del usuario
                        "/usr/bin/gbak",  # Firebird 3.0 (fallback, puede causar problemas de compatibilidad)
                        "/opt/firebird/bin/gbak",
                    ]
                    for ruta in posibles_rutas_linux:
                        if os.path.exists(ruta):
                            gbak_path = ruta
                            logger.info(f"Encontrado gbak en: {ruta}")
                            break
                
                if not gbak_path:
                    logger.error(
                        "No se encontr√≥ gbak en el sistema. "
                        "IMPORTANTE: Las bases de datos son Firebird 2.5, se recomienda usar gbak 2.5.\n"
                        "Opciones:\n"
                        "1. Descargar Firebird 2.5 manualmente desde https://firebirdsql.org/en/downloads/\n"
                        "   Extraer en /opt/firebird2.5/ y crear symlink: sudo ln -s /opt/firebird2.5/bin/gbak /usr/local/bin/gbak\n"
                        "2. O instalar Firebird 3.0 (puede causar problemas al restaurar en servidores 2.5):\n"
                        "   sudo apt-get install firebird3.0-utils\n"
                        "3. O configurar FIREBIRD_GBAK_PATH en settings.py con la ruta completa a gbak 2.5"
                    )
                    return False, None, None
                
                logger.info(f"Usando gbak desde: {gbak_path}")
        
        # Generar nombre de archivo temporal (siempre local, no en servidor remoto)
        fecha_str = datetime.now().strftime("%Y-%m-%d_%H-%M")
        nombre_archivo = f"backup_{fecha_str}.fbk"
        
        # Crear directorio temporal local si no existe
        import tempfile
        temp_dir = tempfile.gettempdir()
        ruta_temporal = os.path.join(temp_dir, f"backup_{empresa.nit_normalizado}_{nombre_archivo}")
        
        try:
            # Ejecutar gbak
            # Si es servidor remoto, usar formato host:ruta_base
            # Si es local, usar ruta_base directamente
            comando = [
                gbak_path,
                '-user', usuario,
                '-pass', contrasena,
                '-b',  # Backup
                '-v',  # Verbose
                ruta_completa,  # Usa ruta_completa (puede ser host:ruta o ruta local)
                ruta_temporal  # Siempre guardar localmente
            ]
            
            logger.info(f"Ejecutando gbak desde: {gbak_path}")
            logger.info(f"Origen: {ruta_completa}")
            logger.info(f"Destino: {ruta_temporal}")
            logger.info(f"‚è≥ Iniciando backup... Esto puede tardar varios minutos dependiendo del tama√±o de la base de datos.")
            
            # Verificar que gbak.exe existe antes de ejecutar
            if not os.path.exists(gbak_path):
                logger.error(f"gbak.exe no existe en: {gbak_path}")
                return False, None, None
            
            # Usar Popen para capturar salida en tiempo real y mostrar progreso
            import time
            import threading
            
            # Redirigir stdout y stderr a archivos temporales para evitar bloqueos de buffer
            stdout_file = os.path.join(temp_dir, f"gbak_stdout_{empresa.nit_normalizado}_{int(time.time())}.log")
            stderr_file = os.path.join(temp_dir, f"gbak_stderr_{empresa.nit_normalizado}_{int(time.time())}.log")
            
            stdout_fd = open(stdout_file, 'w')
            stderr_fd = open(stderr_file, 'w')
            
            # Configurar variables de entorno para manejar caracteres especiales
            env = os.environ.copy()
            # Establecer codificaci√≥n UTF-8 para manejar caracteres especiales de Windows (como √ë)
            env['LC_ALL'] = 'C.UTF-8'
            env['LANG'] = 'C.UTF-8'
            
            proceso = subprocess.Popen(
                comando,
                stdout=stdout_fd,
                stderr=stderr_fd,
                text=True,
                env=env  # Pasar variables de entorno
            )
            
            # Monitorear el proceso y mostrar progreso cada 30 segundos
            inicio = time.time()
            ultimo_log = inicio
            ultimo_tamano = 0
            ultimo_progreso = inicio  # Inicializar desde el inicio
            timeout_total = 1800  # 30 minutos m√°ximo
            timeout_sin_progreso = 300  # 5 minutos sin crecimiento del archivo = colgado
            timeout_archivo_no_existe = 120  # 2 minutos sin que exista el archivo = bloqueado
            
            logger.info(f"‚è≥ Monitoreando proceso gbak (PID: {proceso.pid})...")
            logger.info(f"   Timeouts: total={timeout_total//60}min, sin_progreso={timeout_sin_progreso//60}min, archivo_no_existe={timeout_archivo_no_existe}s")
            
            while True:
                # Verificar si termin√≥
                if proceso.poll() is not None:
                    codigo_salida = proceso.returncode
                    logger.info(f"‚úÖ Proceso gbak termin√≥ con c√≥digo: {codigo_salida}")
                    break
                
                tiempo_transcurrido = time.time() - inicio
                
                # Verificar timeout total
                if tiempo_transcurrido > timeout_total:
                    proceso.kill()
                    logger.error(f"‚è±Ô∏è Timeout total: El backup tard√≥ m√°s de {timeout_total//60} minutos")
                    logger.error(f"   Proceso gbak (PID: {proceso.pid}) fue terminado forzosamente")
                    return False, None, None
                
                # Verificar si el archivo est√° creciendo (detectar procesos colgados)
                tamano_actual = 0
                archivo_existe = os.path.exists(ruta_temporal)
                
                if archivo_existe:
                    tamano_actual = os.path.getsize(ruta_temporal)
                    if tamano_actual > ultimo_tamano:
                        # El archivo est√° creciendo, resetear contador
                        ultimo_tamano = tamano_actual
                        ultimo_progreso = time.time()
                        logger.debug(f"üìà Archivo creciendo: {tamano_actual} bytes (+{tamano_actual - ultimo_tamano} bytes)")
                    else:
                        # El archivo no est√° creciendo
                        tiempo_sin_progreso = time.time() - ultimo_progreso
                        if tiempo_sin_progreso > timeout_sin_progreso:
                            proceso.kill()
                            logger.error(f"‚è±Ô∏è Timeout sin progreso: El archivo no ha crecido en {timeout_sin_progreso//60} minutos. Proceso probablemente colgado.")
                            logger.error(f"   Tama√±o del archivo: {tamano_actual} bytes (sin cambios)")
                            logger.error(f"   Proceso gbak (PID: {proceso.pid}) fue terminado forzosamente")
                            logger.error(f"   Tiempo transcurrido: {int(tiempo_transcurrido//60)} minutos")
                            return False, None, None
                else:
                    # Archivo no existe a√∫n - verificar si el proceso est√° bloqueado
                    tiempo_sin_archivo = tiempo_transcurrido
                    # Mostrar advertencia cada 30 segundos si el archivo no existe
                    if tiempo_sin_archivo > 30 and int(tiempo_sin_archivo) % 30 < 2:
                        logger.warning(f"‚ö†Ô∏è Archivo de backup a√∫n no existe despu√©s de {int(tiempo_sin_archivo)} segundos...")
                        logger.warning(f"   Ruta esperada: {ruta_temporal}")
                        logger.warning(f"   Si el archivo no aparece en {timeout_archivo_no_existe} segundos, el proceso ser√° terminado")
                    
                    if tiempo_sin_archivo > timeout_archivo_no_existe:
                        proceso.kill()
                        logger.error(f"‚è±Ô∏è Timeout: El archivo de backup no se cre√≥ despu√©s de {timeout_archivo_no_existe} segundos ({timeout_archivo_no_existe//60} minutos)")
                        logger.error(f"   Ruta esperada: {ruta_temporal}")
                        logger.error(f"   Proceso gbak (PID: {proceso.pid}) probablemente bloqueado esperando respuesta de Firebird")
                        logger.error(f"   Empresa: {empresa.nombre}")
                        if hasattr(empresa, 'servidor') and empresa.servidor:
                            logger.error(f"   Servidor: {empresa.servidor.host}:{empresa.servidor.puerto}")
                        logger.error(f"   Base de datos: {empresa.ruta_base}")
                        logger.error(f"   Proceso fue terminado forzosamente")
                        
                        # Intentar leer stderr para ver si hay alg√∫n error
                        try:
                            if os.path.exists(stderr_file):
                                with open(stderr_file, 'r') as f:
                                    stderr_content = f.read()
                                    if stderr_content:
                                        logger.error(f"   √öltimos errores de gbak:\n{stderr_content[-500:]}")  # √öltimos 500 caracteres
                        except Exception as e:
                            logger.warning(f"   No se pudo leer stderr: {e}")
                        
                        return False, None, None
                
                # Mostrar progreso cada 30 segundos (SIEMPRE mostrar el tama√±o actual)
                if time.time() - ultimo_log >= 30:
                    minutos = int(tiempo_transcurrido // 60)
                    segundos = int(tiempo_transcurrido % 60)
                    tamano_mb = tamano_actual / (1024 * 1024)  # Mostrar tama√±o ACTUAL, no el √∫ltimo registrado
                    logger.info(f"‚è≥ Backup en progreso... Tiempo: {minutos}m {segundos}s, Tama√±o: {tamano_mb:.2f} MB")
                    ultimo_log = time.time()
                
                time.sleep(2)  # Verificar cada 2 segundos
            
            # Esperar a que termine el proceso (ya est√° siendo monitoreado en el while)
            proceso.wait()
            stdout_fd.close()
            stderr_fd.close()
            
            # Leer stdout y stderr de los archivos
            stdout = ""
            if os.path.exists(stdout_file):
                with open(stdout_file, 'r') as f:
                    stdout = f.read()
                try:
                    os.remove(stdout_file)
                except:
                    pass
            
            stderr = ""
            if os.path.exists(stderr_file):
                with open(stderr_file, 'r') as f:
                    stderr = f.read()
                try:
                    os.remove(stderr_file)
                except:
                    pass
            
            resultado = type('obj', (object,), {
                'returncode': proceso.returncode,
                'stdout': stdout,
                'stderr': stderr
            })()
            
            tiempo_total = time.time() - inicio
            logger.info(f"‚úÖ gbak termin√≥ en {int(tiempo_total//60)}m {int(tiempo_total%60)}s")
            
            if resultado.returncode != 0:
                error_msg = resultado.stderr.strip() if resultado.stderr else "Error desconocido"
                logger.error(f"‚ùå Error ejecutando gbak para {empresa.nombre}:")
                logger.error(f"   C√≥digo de salida: {resultado.returncode}")
                logger.error(f"   Error: {error_msg}")
                
                # Detectar errores comunes y dar sugerencias
                if "Unable to complete network request" in error_msg or "Error reading data from the connection" in error_msg:
                    logger.error(f"   üîç Problema de conexi√≥n detectado:")
                    logger.error(f"      - Verificar que el servidor {ruta_completa.split(':')[0]} est√© accesible")
                    logger.error(f"      - Verificar que Firebird est√© corriendo en el servidor remoto")
                    logger.error(f"      - Verificar firewall y VPN")
                elif "timeout" in error_msg.lower():
                    logger.error(f"   üîç Timeout detectado: El backup tard√≥ demasiado")
                
                return False, None, None
            
            # Verificar que el archivo se cre√≥
            if not os.path.exists(ruta_temporal):
                logger.error(f"El archivo de backup no se cre√≥: {ruta_temporal}")
                return False, None, None
            
            tamano = os.path.getsize(ruta_temporal)
            return True, ruta_temporal, tamano
            
        except subprocess.TimeoutExpired:
            logger.error(f"‚è±Ô∏è Timeout al crear backup para {empresa.nombre} (m√°s de 30 minutos)")
            logger.error(f"   Esto puede indicar:")
            logger.error(f"   - Problemas de conexi√≥n de red")
            logger.error(f"   - Base de datos muy grande")
            logger.error(f"   - Servidor remoto no responde")
            return False, None, None
        except Exception as e:
            logger.error(f"Error creando backup para {empresa.nombre}: {e}", exc_info=True)
            return False, None, None
    
    def subir_backup_a_s3(
        self,
        empresa: EmpresaServidor,
        ruta_archivo_local: str,
        nombre_archivo: str
    ) -> Tuple[bool, Optional[str]]:
        """
        Sube un archivo de backup a S3.
        
        Args:
            empresa: Empresa para la cual se sube el backup
            ruta_archivo_local: Ruta local del archivo de backup
            nombre_archivo: Nombre del archivo en S3
            
        Returns:
            Tupla (√©xito, ruta_s3)
        """
        if not os.path.exists(ruta_archivo_local):
            logger.error(f"Archivo no existe: {ruta_archivo_local}")
            return False, None
        
        try:
            ruta_s3 = self.obtener_ruta_s3(empresa, nombre_archivo)
            
            # Subir archivo
            # Nota: Contabo S3 puede no soportar ServerSideEncryption, as√≠ que lo removemos
            # Si necesitas encriptaci√≥n, hazlo localmente antes de subir
            # No pasar ExtraArgs si est√° vac√≠o (igual que en el test que funciona)
            
            tamano_archivo = os.path.getsize(ruta_archivo_local)
            tamano_mb = tamano_archivo / (1024 * 1024)
            
            logger.info(f"‚òÅÔ∏è Iniciando subida a S3: bucket={self.bucket_name}, key={ruta_s3}")
            logger.info(f"   Archivo local: {ruta_archivo_local} ({tamano_mb:.2f} MB / {tamano_archivo} bytes)")
            logger.info(f"   Timeout configurado: connect=30s, read=300s (5 min)")
            
            # Usar upload_file sin ExtraArgs (igual que el test exitoso)
            # El timeout est√° configurado en BotoConfig (connect_timeout=30, read_timeout=300)
            inicio_upload = time.time()
            self.s3_client.upload_file(
                ruta_archivo_local,
                self.bucket_name,
                ruta_s3
            )
            tiempo_upload = time.time() - inicio_upload
            
            logger.info(f"‚úÖ Backup subido exitosamente a S3: {ruta_s3} (tiempo: {tiempo_upload:.2f}s, velocidad: {tamano_mb/tiempo_upload:.2f} MB/s)")
            
            # Registrar backup exitoso en el log
            try:
                peso_bytes = os.path.getsize(ruta_archivo_local)
                self.registrar_backup_en_log(
                    empresa=empresa,
                    exito=True,
                    peso_bytes=peso_bytes,
                    nombre_archivo=nombre_archivo
                )
            except Exception as e:
                # No fallar el backup si falla el registro en el log
                logger.warning(f"No se pudo registrar backup en log para {empresa.nombre}: {e}")
            
            return True, ruta_s3
            
        except ClientError as e:
            logger.error(f"Error de AWS S3 al subir backup: {e}")
            return False, None
        except Exception as e:
            logger.error(f"Error inesperado al subir backup: {e}", exc_info=True)
            return False, None
    
    def eliminar_backup_s3(self, ruta_s3: str) -> bool:
        """
        Elimina un archivo de backup de S3.
        
        Args:
            ruta_s3: Ruta completa del archivo en S3
            
        Returns:
            True si se elimin√≥ exitosamente
        """
        try:
            self.s3_client.delete_object(Bucket=self.bucket_name, Key=ruta_s3)
            logger.info(f"Backup eliminado de S3: {ruta_s3}")
            return True
        except Exception as e:
            logger.error(f"Error eliminando backup de S3: {e}")
            return False
    
    def necesita_backup_anio_anterior(self, empresa: EmpresaServidor) -> Tuple[bool, Optional[int]]:
        """
        Verifica si una empresa de a√±o fiscal anterior necesita backup.
        
        Args:
            empresa: Empresa para la cual verificar
            
        Returns:
            Tupla (necesita_backup, anio_fiscal) si necesita, (False, None) si no
        """
        from datetime import timedelta
        
        anio_fiscal_actual = empresa.anio_fiscal
        fecha_actual = timezone.now()
        treinta_dias_atras = fecha_actual - timedelta(days=30)
        
        # Solo verificar empresas de a√±os fiscales anteriores
        if empresa.anio_fiscal >= date.today().year:
            return False, None
        
        # Buscar el backup m√°s reciente de este a√±o fiscal
        backup_mas_reciente = BackupS3.objects.filter(
            empresa_servidor=empresa,
            anio_fiscal=empresa.anio_fiscal,
            estado='completado'
        ).order_by('-fecha_backup').first()
        
        # Si no hay backup o tiene m√°s de 30 d√≠as, necesita backup
        if not backup_mas_reciente:
            return True, empresa.anio_fiscal
        
        if backup_mas_reciente.fecha_backup.replace(tzinfo=None) < treinta_dias_atras.replace(tzinfo=None):
            logger.info(f"Backup de a√±o fiscal {empresa.anio_fiscal} tiene m√°s de 30 d√≠as, necesita reemplazo")
            return True, empresa.anio_fiscal
        
        return False, None
    
    def aplicar_politica_retencion(self, empresa: EmpresaServidor) -> Dict[str, int]:
        """
        Aplica la pol√≠tica de retenci√≥n de backups:
        - A√±os fiscales anteriores: 1 backup por a√±o (reemplazar si tiene m√°s de 30 d√≠as)
        - A√±o fiscal actual: m√°ximo 3 backups (3 d√≠as)
        
        Args:
            empresa: Empresa para la cual aplicar la pol√≠tica
            
        Returns:
            Diccionario con estad√≠sticas de eliminaci√≥n
        """
        from datetime import timedelta
        
        anio_actual = date.today().year
        anio_fiscal_actual = empresa.anio_fiscal
        fecha_actual = timezone.now()
        treinta_dias_atras = fecha_actual - timedelta(days=30)
        
        # Obtener todos los backups de la empresa
        backups = BackupS3.objects.filter(
            empresa_servidor=empresa,
            estado='completado'
        ).order_by('anio_fiscal', '-fecha_backup')
        
        eliminados = 0
        conservados = 0
        
        # Agrupar por a√±o fiscal
        backups_por_anio = {}
        for backup in backups:
            anio = backup.anio_fiscal
            if anio not in backups_por_anio:
                backups_por_anio[anio] = []
            backups_por_anio[anio].append(backup)
        
        # Aplicar pol√≠tica
        for anio, backups_anio in backups_por_anio.items():
            if anio < anio_fiscal_actual:
                # A√±os anteriores: conservar solo el m√°s reciente
                # Si el m√°s reciente tiene m√°s de 1 mes, eliminarlo para que se cree uno nuevo
                backups_ordenados = sorted(backups_anio, key=lambda b: b.fecha_backup, reverse=True)
                backup_mas_reciente = backups_ordenados[0] if backups_anio else None
                
                # Eliminar todos excepto el m√°s reciente
                for backup in backups_ordenados[1:]:
                    if self.eliminar_backup_s3(backup.ruta_s3):
                        backup.delete()
                        eliminados += 1
                
                # Si el backup m√°s reciente tiene m√°s de 30 d√≠as, eliminarlo para mantenerlo fresco
                if backup_mas_reciente:
                    if backup_mas_reciente.fecha_backup.replace(tzinfo=None) < treinta_dias_atras.replace(tzinfo=None):
                        logger.info(f"Backup de a√±o fiscal {anio} tiene m√°s de 30 d√≠as ({backup_mas_reciente.fecha_backup}), eliminando para mantenerlo fresco")
                        if self.eliminar_backup_s3(backup_mas_reciente.ruta_s3):
                            backup_mas_reciente.delete()
                            eliminados += 1
                        conservados = 0  # Se reemplazar√° en el pr√≥ximo backup
                    else:
                        conservados = 1  # Conservar el m√°s reciente
                else:
                    conservados = 0
                    
            elif anio == anio_fiscal_actual:
                # A√±o fiscal actual: conservar m√°ximo 3 backups (3 d√≠as)
                backups_ordenados = sorted(backups_anio, key=lambda b: b.fecha_backup, reverse=True)
                for backup in backups_ordenados[3:]:  # Eliminar todos despu√©s del 3ro
                    if self.eliminar_backup_s3(backup.ruta_s3):
                        backup.delete()
                        eliminados += 1
                conservados += min(3, len(backups_ordenados))
        
        return {
            'eliminados': eliminados,
            'conservados': conservados
        }
    
    def verificar_limite_espacio(self, empresa: EmpresaServidor) -> Tuple[bool, float, float]:
        """
        Verifica si la empresa ha excedido su l√≠mite de espacio.
        
        Args:
            empresa: Empresa para verificar
            
        Returns:
            Tupla (excede_limite, tamano_actual_gb, limite_gb)
        """
        try:
            tamano_actual = self.obtener_tamano_actual_gb(empresa)
        except Exception as e:
            # Si no se puede calcular el tama√±o (problema de conexi√≥n S3), 
            # asumimos 0 y continuamos (no bloqueamos el backup)
            logger.warning(f"No se pudo calcular tama√±o actual para {empresa.nombre}: {e}. Continuando con backup.")
            tamano_actual = 0.0

        # El l√≠mite es por empresa (NIT normalizado), no por a√±o fiscal individual.
        # Tomamos el mayor l√≠mite configurado entre todos los a√±os fiscales de ese NIT,
        # para evitar que un a√±o con l√≠mite m√°s bajo bloquee al resto.
        from ..models import EmpresaServidor as EmpresaServidorModel
        empresas_mismo_nit = EmpresaServidorModel.objects.filter(
            nit_normalizado=empresa.nit_normalizado
        )
        if empresas_mismo_nit.exists():
            limite = max(e.limite_espacio_gb for e in empresas_mismo_nit)
        else:
            limite = empresa.limite_espacio_gb
        
        excede = tamano_actual >= limite
        
        return excede, tamano_actual, limite
    
    def realizar_backup_completo(
        self,
        empresa: EmpresaServidor,
        gbak_path: Optional[str] = None,  # None = buscar autom√°ticamente
        usuario: str = "SYSDBA",
        contrasena: str = "masterkey"
    ) -> Tuple[bool, Optional[BackupS3], Optional[str]]:
        """
        Realiza un backup completo: crea el backup local, lo sube a S3 y aplica pol√≠tica de retenci√≥n.
        
        Args:
            empresa: Empresa para la cual realizar el backup
            gbak_path: Ruta al ejecutable gbak.exe
            usuario: Usuario de Firebird
            contrasena: Contrase√±a de Firebird
            
        Returns:
            Tupla (√©xito, objeto_backup_s3, mensaje_error)
        """
        # Verificar l√≠mite de espacio
        excede, tamano_actual, limite = self.verificar_limite_espacio(empresa)
        if excede:
            mensaje = f"L√≠mite de espacio excedido: {tamano_actual:.2f} GB / {limite} GB"
            logger.warning(f"Backup no realizado para {empresa.nombre}: {mensaje}")
            return False, None, mensaje
        
        # Crear backup local
        logger.info(f"üì¶ Creando backup local con gbak para {empresa.nombre}...")
        exito, ruta_local, tamano = self.crear_backup_firebird(empresa, gbak_path, usuario, contrasena)
        if not exito:
            error_msg = "Error al crear backup local"
            logger.error(f"‚ùå {error_msg} para {empresa.nombre}")
            # Registrar error en log
            try:
                self.registrar_backup_en_log(
                    empresa=empresa,
                    exito=False,
                    error=error_msg
                )
            except Exception as e:
                logger.warning(f"No se pudo registrar error en log: {e}")
            return False, None, error_msg
        
        tamano_mb = tamano / (1024 * 1024) if tamano else 0
        logger.info(f"‚úÖ Backup local creado: {os.path.basename(ruta_local)} ({tamano_mb:.2f} MB)")
        
        nombre_archivo = os.path.basename(ruta_local)
        
        try:
            # Subir a S3
            logger.info(f"‚òÅÔ∏è Subiendo backup a S3 (Contabo) para {empresa.nombre}...")
            exito_upload, ruta_s3 = self.subir_backup_a_s3(empresa, ruta_local, nombre_archivo)
            if not exito_upload:
                error_msg = "Error al subir backup a S3"
                logger.error(f"‚ùå {error_msg} para {empresa.nombre}")
                # Registrar error en log
                try:
                    self.registrar_backup_en_log(
                        empresa=empresa,
                        exito=False,
                        peso_bytes=tamano,
                        nombre_archivo=nombre_archivo,
                        error=error_msg
                    )
                except Exception as e:
                    logger.warning(f"No se pudo registrar error en log: {e}")
                # Limpiar archivo local
                if os.path.exists(ruta_local):
                    os.remove(ruta_local)
                return False, None, error_msg
            
            logger.info(f"‚úÖ Backup subido exitosamente a S3: {ruta_s3}")
            
            # Registrar en BD
            logger.info(f"üíæ Creando registro en base de datos para {empresa.nombre}...")
            backup_s3 = BackupS3.objects.create(
                empresa_servidor=empresa,
                configuracion_s3=self.config,
                ruta_s3=ruta_s3,
                nombre_archivo=nombre_archivo,
                tamano_bytes=tamano,
                fecha_backup=timezone.now(),
                anio_fiscal=empresa.anio_fiscal,
                estado='completado'
            )
            logger.info(f"‚úÖ Registro creado: BackupS3 ID {backup_s3.id}")
            
            # Aplicar pol√≠tica de retenci√≥n
            logger.info(f"üßπ Aplicando pol√≠tica de retenci√≥n para {empresa.nombre}...")
            stats = self.aplicar_politica_retencion(empresa)
            logger.info(f"‚úÖ Pol√≠tica aplicada: {stats['eliminados']} eliminados, {stats['conservados']} conservados")
            
            # Limpiar archivo local
            if os.path.exists(ruta_local):
                os.remove(ruta_local)
            
            logger.info(f"üéâ Backup completado exitosamente para {empresa.nombre}: {ruta_s3}")
            return True, backup_s3, None
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"Error en backup completo para {empresa.nombre}: {error_msg}", exc_info=True)
            # Registrar error en log
            try:
                self.registrar_backup_en_log(
                    empresa=empresa,
                    exito=False,
                    error=error_msg
                )
            except Exception as log_error:
                logger.warning(f"No se pudo registrar error en log: {log_error}")
            # Limpiar archivo local
            if os.path.exists(ruta_local):
                os.remove(ruta_local)
            return False, None, error_msg
    
    def listar_backups(self, empresa: EmpresaServidor) -> List[Dict]:
        """
        Lista todos los backups de una empresa en S3.
        
        Args:
            empresa: Empresa para la cual listar backups
            
        Returns:
            Lista de diccionarios con informaci√≥n de backups
        """
        backups = BackupS3.objects.filter(
            empresa_servidor=empresa
        ).order_by('-fecha_backup')
        
        return [
            {
                'id': b.id,
                'nombre_archivo': b.nombre_archivo,
                'ruta_s3': b.ruta_s3,
                'tamano_mb': b.tamano_mb,
                'tamano_gb': b.tamano_gb,
                'fecha_backup': b.fecha_backup.isoformat(),
                'anio_fiscal': b.anio_fiscal,
                'estado': b.estado,
            }
            for b in backups
        ]
    
    def eliminar_backup(self, backup_id: int) -> bool:
        """
        Elimina un backup espec√≠fico de S3 y de la BD.
        
        Args:
            backup_id: ID del backup a eliminar
            
        Returns:
            True si se elimin√≥ exitosamente
        """
        try:
            backup = BackupS3.objects.get(id=backup_id)
            ruta_s3 = backup.ruta_s3
            
            if self.eliminar_backup_s3(ruta_s3):
                backup.delete()
                return True
            return False
        except BackupS3.DoesNotExist:
            logger.error(f"Backup con ID {backup_id} no existe")
            return False
        except Exception as e:
            logger.error(f"Error eliminando backup: {e}")
            return False

